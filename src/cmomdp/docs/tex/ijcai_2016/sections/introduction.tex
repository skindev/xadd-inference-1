\section{Introduction}
\label{sec:introduction}

Markov Decision Processes (MDPs)~\parencite{Howard_MIT_1960} are the de facto standard framework for decision theoretic
planning in fully observable environments~\parencite{Boutilier_JAIR_1999}. MDPs occur in a wide range of real world domains such as game playing~\parencite{Szita_RL_2012}, power systems~\parencite{Reddy_IJCAI_2011}, ecology~\parencite{Williams_EM_2009} and patient admission scheduling~\parencite{Zhu_AIM_2014}. Traditional MDP solution techniques often assume that the parameters of the model are known. However, in practice, model parameters are usually estimated and uncertain. It is often critical in real world applications to: (i) investigate the trade-off between multi-objective reward criteria; (ii) perform sensitivity analyses of parameters; and (iii) optimize continuous non-convex policy parameters. Formalizing models to address each of the aforementioned use cases is often fraught, due to the specification often leading to hybrid (mixed discrete and continuous state and/or action) MDPs with non-linear and/or piecewise structure. 

In this paper we make the following key contributions:
\begin{itemize}
    \item We present the unifying framework of parameterized hybrid MDPs which enables the investigation of trade-offs between multi-objective reward criteria, parameter sensitivity and non-convex optimization of policy parameters
    \item We provide an algorithm that solves this class of parameterized hybrid MDPs exactly and in closed-form using Symbolic Dynamic Programming~\parencite{Boutilier_IJCAI_2001}
    \item We use our novel framework to explore, for the first time: (i) an exact functional representation of the multi-objective trade-offs for use in interactive decision maps; (ii) exact sensitivity analysis of public health policies in epidemic models; and (iii) non-convex optimization of policy parameters applied to the optimal execution problem in finance
\end{itemize}

%This paper is organised as follows: In Section~\ref{sec:hybrid_mdps} we describe parameterized hybrid Markov Decision Processes (MDPs) and value iteration~\parencite{Bellman_PU_1957}, a widely used dynamic programming method for solving MDPs. Following this, in Section~\ref{sec:sdp}, we introduce Symbolic Dynamic Programming (SDP), and show how it can be used to calculate exact closed-form solutions to parameterized hybrid MDPs. In Section~\ref{sec:results} we calculate exact solutions to three empirical domains: (1) autonomous driving; (2) influenza epidemiology; and (3) optimal trade execution. We conclude in Section~\ref{sec:conclusion} and identify interesting directions for future research.