\begin{abstract}

Markov Decision Processes (MDPs)~\parencite{Howard_MIT_1960} provide a powerful framework for decision theoretic planning. MDPs occur in many real world domains, however their applicability is limited by the common assumption that the model parameters are known. This is not the case in practice, where parameters are usually estimated and uncertain. It is often critical in real world applications to investigate the trade-off between multi-objective reward criteria, sensitivity analyses of parameters and stability of policies. However, formalizing MDPs in this way leads to hybrid MDPs with non-linear and/or piecewise structure. In this paper we present a framework to solve parameterized hybrid MDPs exactly and in closed-form by symbolic dynamic programming. Our novel framework allows one to investigate the sensitivity of optimal value function to hyper-parameters, trade-offs between multiple reward criteria and the stability of optimal policies. We demonstrate efficacy of our framework on domains from autonomous driving, epidemiology and finance.

\end{abstract}
