\begin{abstract}

Markov Decision Processes (MDPs) provide a powerful framework for decision theoretic planning. MDPs occur in many real world domains, however their applicability is limited by the common assumption that the model parameters are known. This is not the case in practice, where parameters are usually estimated and uncertain. It is often critical in real world applications to: (i) investigate the trade-off between multi-objective reward criteria; (ii) perform sensitivity analyses of parameters; and (iii) optimize continuous non-convex policy parameters. However, formalizing MDPs in this way leads to hybrid (mixed discrete and continuous state and/or action) MDPs with non-linear and/or piecewise structure. In this paper we show how each of the aforementioned use cases can be formalized under the common framework of parameterized hybrid MDPs and solved exactly and in closed-form by leveraging techniques from symbolic dynamic programming. Our novel framework allows one to explore for the first-time: (i) an exact functional representation of the multi-objective trade-offs for use in Interactive Decision Maps; (ii) exact sensitivity analysis of public health policies in epidemic models over the full range of infection rate parameters; and (iii) non-convex optimization of policy parameters applied to finance problems previously impossible with sample-based policy gradient techniques.

\end{abstract}
