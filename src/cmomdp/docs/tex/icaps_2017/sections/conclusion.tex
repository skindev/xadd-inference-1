\section{Conclusions}
\label{sec:conclusion}

In this paper we introduced Parameterized Hybrid MDPs as a unifying framework, which enables the inverse learning of parameters of multi-objective rewards, the examination of parameter sensitivity and the non-convex optimization of continuous policy parameters. We also presented a novel algorithm to solve PHMDPs by utilizing a parametric extension of symbolic dynamic programming and state-of-the-art non-convex optimizers. 
%We demonstrated the utility and scalability of our framework by calculating the first known exact solutions to the inverse learning of parameters for multi-objective navigation, non-convex optimization of vaccination policies and sensitivity analysis of trading models.

%There are a number of avenues for future research. Firstly, it is important to examine more general representations of the reward and transition functions while still guaranteeing exact solutions. Another direction of research lies within improving the scalability of the algorithm by either extending techniques for Algebraic Decision Diagrams~\parencite{Bahar_JoFMiSD_1993} from APRICODD~\parencite{St-Aubin_NIPS_2000} under the current restrictions on the reward and transition functions or bounded error compression for XADDs~\parencite{Vianna_UAI_2013} for more expressive representations. The advances made within this paper open up a number of potential novel research paths, which may be used to progress multi-objective analyses, sensitivity analyses and nonlinear parameterized policy optimization for difficult nonlinear sequential decision making problems.
